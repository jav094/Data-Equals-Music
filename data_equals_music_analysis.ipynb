{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data == Music\n",
    "-------------\n",
    "A predictive model that can predict how highly rated \n",
    "music will be based on audio characteristics and \n",
    "track information from Spotify!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recall the steps to making a machine learning model:\n",
    "1. Create a feature matrix and response vector (X and y)\n",
    "2. Import an estimator class\n",
    "3. Instantiate that estimator class\n",
    "4. Fit the model with training data\n",
    "5. Use the model to predict a new observation\n",
    "6. Evaluate the model's accuracy\n",
    "7. ???\n",
    "8. PROFIT!\n",
    "\n",
    "We'll be following steps 1-6 in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import and set up ALL THE THINGS!\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(depth=4)\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "plt.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.color_palette(\"muted\")\n",
    "sns.set_style(\"ticks\", \n",
    "                {'axes.grid': False,\n",
    "                 'axes.linewidth': 0.5,\n",
    "                })\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from DataEqualsMusic import SpotiAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, let's get our data from a .csv into a DataFrame.\n",
    "(FYI, you can update the .csv by running DataEqualsMusic.py.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = \"data/modified_spotify_top_200.csv\"\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# Here's our DataFrame's top 3 entries\n",
    "df.head(3)\n",
    "\n",
    "test = df.drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Our feature columns are everything after \"Position\", which is our response variable.\n",
    "feature_cols = df.columns[2:]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df.Position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we really dig in, let's try to visualize any potential relationships in the data.\n",
    "\n",
    "Are there any overall trends we can see right off the bat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's see if a scatter plot shows us anything.\n",
    "plt.scatter(df[\"energy\"], y)\n",
    "\n",
    "# Set axis limits: energy 0.0 - 1.0, Position 1 - 200\n",
    "plt.axis((0.0,1.0,0,200))\n",
    "\n",
    "# Invert the y axis, we want high ranking to be on top.\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# Vanity\n",
    "sns.despine()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least we can see that most of the top 200 tracks tend to be fairly energetic. Let's see where most of them are relative to the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = df.energy\n",
    "p_25 = np.percentile(e, 25) # Returns 25th percentile of the \"energy\" feature\n",
    "p_50 = np.percentile(e, 50) \n",
    "p_75 = np.percentile(e, 75)\n",
    "\n",
    "# Same plot as before, plus lines for the percentiles\n",
    "plt.scatter(df[\"energy\"], y)\n",
    "plt.axis((0.0,1.0,0,200))\n",
    "plt.gca().invert_yaxis()\n",
    "sns.despine()\n",
    "\n",
    "# Just so we can see them, let's give the lines some colors\n",
    "plt.axvline(x=p_25, color=\"Green\")\n",
    "plt.axvline(x=p_50, color=\"Black\")\n",
    "plt.axvline(x=p_75, color=\"Green\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print p_25, p_50, p_75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well well! From this we can see that most tracks are pretty energetic, like we thought. \n",
    "\n",
    "The median energy level is 0.7, which about the norm for artists like Selena Gomez and David Guetta. Before we assume anything though, we should notice that some artists (like Rihanna and Drake) rank highly despite having low-energy songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's try the same for danceability\n",
    "d = df.danceability\n",
    "p_25 = np.percentile(d, 25)\n",
    "p_50 = np.percentile(d, 50) \n",
    "p_75 = np.percentile(d, 75)\n",
    "plt.scatter(df[\"danceability\"], y)\n",
    "plt.axis((0.0,1.0,0,200))\n",
    "plt.gca().invert_yaxis()\n",
    "sns.despine()\n",
    "plt.axvline(x=p_25, color=\"Green\")\n",
    "plt.axvline(x=p_50, color=\"Black\")\n",
    "plt.axvline(x=p_75, color=\"Green\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print p_25, p_50, p_75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be honest I'm disappointed that most songs have such low danceability, I expected higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find out most predictive feature with correlation matrix\n",
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A track's Position in the global Top 200 charts seems to be:\n",
    "* Slightly negatively correlated with the track's key\n",
    "* Slightly positively correlated with the track's mode and duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create a feature matrix and response vector (X and y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our feature columns are everything after \"Position\", which is our response variable.\n",
    "feature_cols = df.columns[2:]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df.Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's take a look at the shape of our data.\n",
    "print X.shape # 200,14. Makes sense; 200 rows and 14 features.\n",
    "print y.shape # 200,\n",
    "\n",
    "print X_train.shape # 150, 14\n",
    "print X_test.shape # 50, 14\n",
    "print y_train.shape # 150,\n",
    "print y_test.shape # 50,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "At this point, I attempted to make a logistic regression model, fit it to the data, and make predictions with it. \n",
    "\n",
    "However, that turned out to be _incredibly_ non-predictive so I scrapped it. \n",
    "\n",
    "Unfortunately, I didn't keep a copy for posterity so we're just going to move on to a model that should perform better: RandomForestRegressor!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import an estimator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Technically, we already did this up top but here it is anyway:\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Instantiate that estimator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We'll stick with the default n_estimators=10 for now.\n",
    "# We'll use the same random state throughout this notebook, \n",
    "    # just so that we can be sure no error is due to it.\n",
    "rf = RandomForestRegressor(random_state=1)\n",
    "\n",
    "rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fit the model with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This kind of regressor doesn't need a train/test split, so we'll fit it to all of our data.\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we're at it, let's see the feature importances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importance = pd.DataFrame({'feature':feature_cols, 'importance':rf.feature_importances_}).sort_values('importance', ascending=False)\n",
    "importance.sort_values(\"importance\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Use the model to predict a new observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_prediction = rf.predict(X_train)\n",
    "y_test_prediction = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 6. Evaluate the model's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Untuned, this is the model's accuracy\n",
    "MSE_scores = cross_val_score(rf, X, y, cv=10, scoring='mean_squared_error')\n",
    "RMSE_scores.append(np.mean(np.sqrt(-MSE_scores)))\n",
    "\n",
    "# Let's look at the residuals\n",
    "\n",
    "np.mean(RMSE_scores)\n",
    "# y_train_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning n-estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's tune the model a bit and see where that gets us.\n",
    "\n",
    "# list of values to try for n_estimators\n",
    "estimator_range = range(1, 20)\n",
    "\n",
    "# list to store the average RMSE for each value of max_depth\n",
    "RMSE_scores = []\n",
    "\n",
    "# use 5-fold cross-validation with each value of n_estimators (WARNING: SLOW!)\n",
    "for estimator in estimator_range:\n",
    "    rfreg = RandomForestRegressor(n_estimators=estimator, random_state=1)\n",
    "    MSE_scores = cross_val_score(rfreg, X, y, cv=5, scoring='mean_squared_error')\n",
    "    RMSE_scores.append(np.mean(np.sqrt(-MSE_scores)))\n",
    "    \n",
    "# plot n_estimators (x-axis) versus RMSE (y-axis)\n",
    "plt.plot(estimator_range, RMSE_scores)\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('RMSE (lower is better)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show the best RMSE and the corresponding n_estimators\n",
    "final_n_estimators = sorted(zip(RMSE_scores, estimator_range))[0][1]\n",
    "final_n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning max features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list of values to try for max_features\n",
    "feature_range = range(1, len(feature_cols)+1)\n",
    "\n",
    "# list to store the average RMSE for each value of max_features\n",
    "RMSE_scores = []\n",
    "\n",
    "# use 10-fold cross-validation with each value of max_features (WARNING: SLOW!)\n",
    "for feature in feature_range:\n",
    "    rfreg = RandomForestRegressor(n_estimators=150, max_features=feature, random_state=1)\n",
    "    MSE_scores = cross_val_score(rfreg, X, y, cv=10, scoring='mean_squared_error')\n",
    "    RMSE_scores.append(np.mean(np.sqrt(-MSE_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot max_depth (x-axis) versus RMSE (y-axis)\n",
    "plt.plot(max_depth_range, RMSE_scores)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('RMSE (lower is better)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's visualize the results of our max_features tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
